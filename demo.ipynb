{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于Gzip和kNN的文本分类\n",
    "## 简介\n",
    "### 一 项目介绍\n",
    "#### a 项目描述\n",
    "该项目源于ACL2023的一篇Findings论文《\"Low-Resource\" Text Classification: A Parameter-Free Classification Method with Compressors》。\\\n",
    "论文地址：https://aclanthology.org/2023.findings-acl.426.pdf\n",
    "官方代码：https://github.com/bazingagin/npc_gzip\n",
    "该论文一经发表就引发了热议。文中表示，在没有任何训练参数的情况下，该方法的分类结果能够与多个基于DNN的方法相媲美，并在五个分布外数据集上胜过了包括BERT在内的所有方法。\n",
    "作为一种DNN的轻量级替代方法，它使用无损压缩器（如gzip）和kNN相结合的方法实现文本分类的任务。该方法利用压缩长度来近似柯氏复杂性（Kolmogorov complexity），基于归一化压缩距离（Normalized Compression Distance, NCD）度量文本之间的相似度。\n",
    "#### b 适学人群\n",
    "大一年级及以上，算法初学者，并且有志于从事机器学习、自然语言处理相关岗位的学生。\n",
    "#### c 课程基础\n",
    "掌握Python语言，了解kNN算法。\n",
    "### 二 任务介绍\n",
    "阅读了解并学习掌握如何使用gzip和kNN算法来进行文本分类。\n",
    "### 三 数据集介绍\n",
    "AG_NEWS数据集中包含了4个类别的新闻文本数据集，一共有12万条训练样本和7600条测试样本。\\\n",
    "torchtext中的datasets模块提供了AG_NEWS的数据集获取方法。\\\n",
    "可以在https://huggingface.co/datasets/ag_news预览该数据集。\n",
    "### 四 学习目标\n",
    "通过本项目可以学习到torchtext的数据集加载、gzip的使用方法以及kNN算法的实现。\n",
    "### 五 运行建议\n",
    "无"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchtext.datasets import AG_NEWS\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.设置默认值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中途输出的文件会存在runtime文件夹下\n",
    "output_dir = './runtime'\n",
    "\n",
    "# 下载的数据会存在dataset文件夹下\n",
    "data_dir = './dataset'\n",
    "\n",
    "# 训练集和测试集每个类别随机采样的数量\n",
    "num_train = 1000\n",
    "num_test = 10\n",
    "\n",
    "# 类别个数\n",
    "num_classes = 4\n",
    "\n",
    "# 记录所采样本id的文件位置\n",
    "train_idx_fn = os.path.join(output_dir, 'train_indicies_{}per_class'.format(num_train))\n",
    "test_idx_fn = os.path.join(output_dir, 'test_indicies_{}per_class'.format(num_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从数据集ds中的每个类别随机加载n个数据到output_fn文件地址\n",
    "def pick_samples(ds, n, output_fn):\n",
    "    \n",
    "    # 获取每个类别分别对应的样本和样本id\n",
    "    label2text = defaultdict(list)\n",
    "    label2idx = defaultdict(list)\n",
    "    for i, (label, text) in enumerate(ds):\n",
    "    label2text[label].append(text)\n",
    "    label2idx[label].append(i)\n",
    "    \n",
    "    # 获取每个类别的样本数量\n",
    "    class2count = {}\n",
    "    for cl in label2text:\n",
    "        class2count[cl] = len(label2text[cl])\n",
    "    \n",
    "    # 在每个类别中随机选取n个样本，并记录所选样本的id\n",
    "    result = []\n",
    "    labels = []\n",
    "    recorded_idx = []\n",
    "    for c in class2count:\n",
    "        select_idx = np.random.choice(class2count[c], size=n, replace=False)\n",
    "        select_text = np.array(label2text[c])[select_idx]\n",
    "        select_text_idx = np.array(label2idx[c])[select_idx]\n",
    "        recorded_idx+=list(select_text_idx)\n",
    "        result+=list(select_text)\n",
    "        labels+=[c]*n\n",
    "    \n",
    "    # 将所选取样本的id存储到文件中\n",
    "    if output_fn is not None:\n",
    "        np.save(output_fn, np.array(recorded_idx))\n",
    "    \n",
    "    return result, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载全部数据（后续计算距离用于推断的时间过长）\n",
    "# def load_all(ds):\n",
    "#     result = []\n",
    "#     labels = []\n",
    "#     for i, (label, line) in enumerate(ds):\n",
    "#         result.append(line)\n",
    "#         labels.append(label)\n",
    "#     return result, labels\n",
    "# train_data, train_labels = load_all(dataset_pair[0])\n",
    "# test_data, test_labels = load_all(dataset_pair[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pair = AG_NEWS(root=data_dir)\n",
    "train_data, train_labels = pick_samples(dataset_pair[0], num_train, train_idx_fn)\n",
    "test_data, test_labels = pick_samples(dataset_pair[1], num_test, test_idx_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 计算文本之间距离\n",
    "这里采用归一化压缩距离（NCD）作为距离指标。\\\n",
    "NCD的计算公式如下：\n",
    "$$NCD(x,y) = \\frac{C(xy)-{\\rm min}\\{C(x),C(y)\\}}{{\\rm max}\\{C(x),C(y)\\}}$$\n",
    "其中$C(x)$为文本$x$的压缩后长度，$C(xy)$将为文本$x$和文本$y$连接后进行压缩的长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NCD(x, y):\n",
    "    c_x = len(gzip.compress(x.encode('utf-8')))\n",
    "    c_y = len(gzip.compress(y.encode('utf-8')))s\n",
    "    c_xy = len(gzip.compress((c_x+' '+c_y).encode('utf-8')))\n",
    "    distance = (c_xy-min(c_x,c_y))/max(c_x, c_y)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_dist_single_multi(t1,t2_list):\n",
    "    distances = []\n",
    "    for j, t2 in enumerate(t2_list):\n",
    "        distance = NCD(t1, t2)\n",
    "        distances.append(distance)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_dist(test_data, train_data): \n",
    "    dis_matrix = []\n",
    "    for _, t in tqdm(enumerate(test_data)):\n",
    "        distances = cal_dist_single_multi(t, train_data)\n",
    "        dis_matrix.append(distances)\n",
    "    return dis_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:10,  3.79it/s]\n"
     ]
    }
   ],
   "source": [
    "dis = cal_dist(test_data, train_data)\n",
    "np.save(output_dir+'/dis.npy', np.array(dis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(dis, train_labels, k):\n",
    "    preds = []\n",
    "    for i in range(len(dis)):\n",
    "        # 将第i个测试样本的距离列表排序，得到距离最近的k个训练样本\n",
    "        sorted_idx = np.argsort(np.array(dis[i])) # 按距离排序\n",
    "        pred_labels = defaultdict(int)\n",
    "        # 统计前k个样本中的标签出现次数\n",
    "        for j in range(k):\n",
    "            pred_l = train_labels[sorted_idx[j]]\n",
    "            pred_labels[pred_l] += 1\n",
    "        sorted_pred_lab = sorted(pred_labels.items(), key=operator.itemgetter(1), reverse=True) # 按出现次数排序\n",
    "        most_label = sorted_pred_lab[0][0]\n",
    "        preds.append(most_label)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc(dis, test_labels, train_labels):\n",
    "    compare_label = train_labels\n",
    "    start = 0\n",
    "    end = num_classes\n",
    "    correct = []\n",
    "    pred = []\n",
    "    for i in range(len(dis)):\n",
    "        sorted_idx = np.argsort(np.array(dis[i]))\n",
    "        pred_labels = defaultdict(int)\n",
    "        for j in range(start, end):\n",
    "            pred_l = compare_label[sorted_idx[j]]\n",
    "            pred_labels[pred_l] += 1\n",
    "        sorted_pred_lab = sorted(pred_labels.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        most_count = sorted_pred_lab[0][1]\n",
    "        if_right = 0\n",
    "        most_label = sorted_pred_lab[0][0]\n",
    "        most_voted_labels = []\n",
    "        for pair in sorted_pred_lab:\n",
    "            if pair[1] < most_count:\n",
    "                break\n",
    "            if pair[0] == test_labels[i]:\n",
    "                if_right = 1\n",
    "                most_label = pair[0]\n",
    "            else:\n",
    "                most_voted_labels.append(pair[0])\n",
    "        pred.append(most_label)\n",
    "        correct.append(if_right)\n",
    "    print(\"Accuracy is {}\".format(sum(correct)/len(correct)))\n",
    "    return pred, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.95\n"
     ]
    }
   ],
   "source": [
    "pred, correct = cal_acc(dis,test_labels, train_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
